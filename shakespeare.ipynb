{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from slm import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the data from public online repositories (here, Andrej Karpathy's full texts of Shakespeare concatenated):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def get_data(url, save_file):\n",
    "    try:\n",
    "        with open(save_file, 'r', encoding='utf-8') as f:\n",
    "            return f.read()\n",
    "    except:\n",
    "        os.system(f\"curl {url} -o {save_file}\")\n",
    "        with open(save_file, 'r', encoding='utf-8') as f:\n",
    "                return f.read()\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n",
    "save_file = 'files/shakespeare.txt'\n",
    "text=get_data(url, save_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting the number of characters in the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters in the full text: 1115394\n",
      "Number of distinct characters (= vocab_size): 65\n",
      "The characters are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "\n",
    "char_to_int = {ch:i for i,ch in enumerate(chars)}\n",
    "int_to_char = {i:ch for i,ch in enumerate(chars)}\n",
    "\n",
    "encode = lambda s : [char_to_int[c] for c in s]\n",
    "decode = lambda l : ''.join([int_to_char[n] for n in l]) \n",
    "\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "\n",
    "print('Total number of characters in the full text:', len(text))\n",
    "print('Number of distinct characters (= vocab_size):', vocab_size)\n",
    "print('The characters are:')\n",
    "''.join(chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the model with the characters as its vocab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's output before training: \n",
      "\n",
      "\n",
      "'DaRsGd,dm:T33uc,bYhDap'KDSQDKffFxRIIyFRvPJL?oJsm'vyheNAytBuufBb&X!vr?Aj.bpRjONcg'&,x'u\n",
      "-delVjwuOC ?DAnmC\n",
      "sZR k$NzexNJCNfoxfWjpnw!m3ELAehQ&?uL$FOystwqkiIg'j!L3,-Bglcj'vzOdMLWhvT!\n",
      "f!p33?wixS!.vFxeWW RXQCLA,N& .TLP,m\n",
      "wFjdVrBzQxi:,?YVvpK\n",
      "ITyPJJbYwXRctZ$NcvPSHVi.DIPu Siphw$UUEQl PWslj:yriF?mBw-KI,tpREou;,fsMGTeh$rF!cap3voAmui;YNusxNUTEiLvIEtKGSBv3 d.ijc-Zz$nIcB$Ocei-wbf!EPi$NI;ip,yNpRN, $q!Vu,IDIS-acISeQ$eNt&iZEZym$IXIPpmZyWpzI? t,I?irBIUA,&RIw$wWS-SruzmPueULaeELkYKHdWpupSocLWbEiKj$uOoWstSofA,$OsockwMhZkIpu!CuswfIwmNSOqW'qfpe:PK?v'eZnWKGqIgZ:zcQwlfsAM?cbrmk3zlIe,3$nnw-fKCNBOUjrsSkEUU hStv'IC3GOTeBJrz yLhBCtC;\n",
      ",wVv\n",
      "-PTxjo;,PFUOVP-IE\n",
      "qf'epC',lZIueZoEiUSx:W'M\n",
      "IsNxsZq$33I;pQnZZxb,fxI?qsIe,B\n",
      "!FeA'SJE$XfhIzK!.EreCLO.HfwNcZbh$o:uE,-ISoP'qPh;ah'!Ew!SCAu,-mxxKSDdeSVEFsZTLp,S,wiGKDeYPHUlUERBctIU3I$hyTerabWcNez!:gE,!jpzQ,?txOUp&rITD!ippoB:'s,wrsseYy$GbZth,D.iEI?fKpnpzMcjEBrrIlxVRi'VYlUZBSTkCevT!aEi\n",
      "tyMUEwm!OCac&hI!becFf pa-'YyB&O!dC\n",
      "$Nd DwxccLK!XhSPANACixlcsg eLoCIgUEmBCBNGXc;Yw'Ii\n",
      "wFOLaod-UNOF?-PVBi\n"
     ]
    }
   ],
   "source": [
    "name = 'shake2'\n",
    "model = SLM(chars, name)\n",
    "print(\"Model's output before training:\",'\\n')\n",
    "model.snippet()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading a model checkpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while loading model checkpoint.\n",
      "Total number of parameters: 7383617 \n",
      "\n",
      "Model's layers:\n",
      "\n",
      "token_embedding_table.weight \t torch.Size([65, 768])\n",
      "position_embedding_table.weight \t torch.Size([256, 768])\n",
      "blocks.0.att.heads.0.tril \t torch.Size([256, 256])\n",
      "blocks.0.att.heads.0.key.weight \t torch.Size([128, 768])\n",
      "blocks.0.att.heads.0.query.weight \t torch.Size([128, 768])\n",
      "blocks.0.att.heads.0.value.weight \t torch.Size([128, 768])\n",
      "blocks.0.att.heads.1.tril \t torch.Size([256, 256])\n",
      "blocks.0.att.heads.1.key.weight \t torch.Size([128, 768])\n",
      "blocks.0.att.heads.1.query.weight \t torch.Size([128, 768])\n",
      "blocks.0.att.heads.1.value.weight \t torch.Size([128, 768])\n",
      "blocks.0.att.heads.2.tril \t torch.Size([256, 256])\n",
      "blocks.0.att.heads.2.key.weight \t torch.Size([128, 768])\n",
      "blocks.0.att.heads.2.query.weight \t torch.Size([128, 768])\n",
      "blocks.0.att.heads.2.value.weight \t torch.Size([128, 768])\n",
      "blocks.0.att.heads.3.tril \t torch.Size([256, 256])\n",
      "blocks.0.att.heads.3.key.weight \t torch.Size([128, 768])\n",
      "blocks.0.att.heads.3.query.weight \t torch.Size([128, 768])\n",
      "blocks.0.att.heads.3.value.weight \t torch.Size([128, 768])\n",
      "blocks.0.att.heads.4.tril \t torch.Size([256, 256])\n",
      "blocks.0.att.heads.4.key.weight \t torch.Size([128, 768])\n",
      "blocks.0.att.heads.4.query.weight \t torch.Size([128, 768])\n",
      "blocks.0.att.heads.4.value.weight \t torch.Size([128, 768])\n",
      "blocks.0.att.heads.5.tril \t torch.Size([256, 256])\n",
      "blocks.0.att.heads.5.key.weight \t torch.Size([128, 768])\n",
      "blocks.0.att.heads.5.query.weight \t torch.Size([128, 768])\n",
      "blocks.0.att.heads.5.value.weight \t torch.Size([128, 768])\n",
      "blocks.0.att.proj.weight \t torch.Size([768, 768])\n",
      "blocks.0.att.proj.bias \t torch.Size([768])\n",
      "blocks.0.mpl.net.0.weight \t torch.Size([3072, 768])\n",
      "blocks.0.mpl.net.0.bias \t torch.Size([3072])\n",
      "blocks.0.mpl.proj.weight \t torch.Size([768, 3072])\n",
      "blocks.0.mpl.proj.bias \t torch.Size([768])\n",
      "blocks.0.pre_ln.weight \t torch.Size([768])\n",
      "blocks.0.pre_ln.bias \t torch.Size([768])\n",
      "blocks.0.post_ln.weight \t torch.Size([768])\n",
      "blocks.0.post_ln.bias \t torch.Size([768])\n",
      "blocks.1.weight \t torch.Size([768])\n",
      "blocks.1.bias \t torch.Size([768])\n",
      "lm_head.weight \t torch.Size([65, 768])\n",
      "lm_head.bias \t torch.Size([65])\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model.load_state_dict(torch.load(\n",
    "        model.config.MODEL_PATH, weights_only=True))\n",
    "    print('Model checkpoint loaded successfully.')\n",
    "except:\n",
    "    print('Error while loading model checkpoint.')\n",
    "    pass\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print('Total number of parameters:', params, '\\n')\n",
    "\n",
    "print(\"Model's layers:\\n\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss = 4.3667, eval loss = 4.3678\n",
      "step 1000: train loss = 1.6783, eval loss = 1.8399\n",
      "step 2000: train loss = 1.4843, eval loss = 1.6801\n",
      "step 3000: train loss = 1.4104, eval loss = 1.6255\n",
      "step 4000: train loss = 1.3723, eval loss = 1.6002\n",
      "step 5000: train loss = 1.3415, eval loss = 1.5950\n",
      "step 6000: train loss = 1.3233, eval loss = 1.5778\n",
      "step 7000: train loss = 1.3085, eval loss = 1.5678\n",
      "step 8000: train loss = 1.2963, eval loss = 1.5710\n",
      "Model's output after training: \n",
      "\n",
      "\n",
      "LADY CAPULET:\n",
      "I win him so: and them, pray you heart mistre\n",
      "Is your hold, togethery percharn a husband.\n",
      "\n",
      "CORIOLANUS:\n",
      "Go we?\n",
      "Who'd should the neighbour's th, I did the put you.\n",
      "\n",
      "ESCALUS:\n",
      "Howest will hunder oakething clock, prising a point wood\n",
      "Which eyes hey issolver crying jewell.\n",
      "\n",
      "MERCUTIO:\n",
      "Unhering you have him, spake of HENRY VI:\n",
      "But yet's a Montague o' them but the death!\n",
      "If thousand mark to keeps have chide\n",
      "With meethrow'd to risedd Julio's eye, sithout of Groom.\n",
      "\n",
      "ROMEO:\n",
      "Nay, die my help we did to more,\n",
      "I am a ve me in this. Thou, how do not,\n",
      "And of joyful ruck my swatch'd his babes lodge\n",
      "To hoppy on for the did be in thy fooling last!\n",
      "So Shalwio lieat Pland May on.\n",
      "And, or father's a cut these blast symovitt?\n",
      "\n",
      "ABHORSON:\n",
      "Good consom us:\n",
      "\n",
      "This danger and stood did mest and of thou not me,\n",
      "And we may brough: yet, so we accession,\n",
      "And with appy God'st ment; childrening nense.\n",
      "Poor Margarland.\n",
      "\n",
      "ISABHORSON:\n",
      "A try is my from the world.\n",
      "Good Clow and murse, and life consome, Lest?\n",
      "\n",
      "Secon\n"
     ]
    }
   ],
   "source": [
    "lr=3e-4\n",
    "weight_L2=5e-2\n",
    "max_iters=20000\n",
    "eval_interval=1000\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_L2) # increased L2 penalty\n",
    "try:\n",
    "    for iter in range(max_iters+1):\n",
    "        if iter % eval_interval==0:\n",
    "            losses = estimate_loss(model, data)\n",
    "            print(f\"step {iter}: train loss = {losses['train']:.4f}, eval loss = {losses['val']:.4f}\")\n",
    "            #torch.save(model.state_dict(), model.config.MODEL_PATH[:-3]+f'_{losses['val'].item():.4f}'+'.pt')\n",
    "        x,y=get_batch(model.config, data, 'train')\n",
    "        logits, loss = model(x,y)\n",
    "        optimizer.zero_grad(set_to_none=True) # why set to none?\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    print(\"Model's output after training:\",'\\n')\n",
    "    torch.save(model.state_dict(), model.config.MODEL_PATH)\n",
    "    model.snippet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed looks like Shakespeare!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HAHAM:\n",
      "I never what my deserve and did dishons proget,\n",
      "And from af anothing note properly.\n",
      "It hate prince. But now, but is this,\n",
      "To warvoteuns of he flowers torm hands they griefs.\n",
      "I lawful nature, why do I ladies now mess view'd\n",
      "To Rome shows swere a a genterings; our woo wax,\n",
      "But swarn to sealth: where are affect up in a sise;\n",
      "And tend in thine, an easy within say gangry.\n",
      "Ferench, I cannot byour foe mild leisthips.\n",
      "\n",
      "KING EDWARD IV:\n",
      "NORGod voice bother Gloucester; and we was\n",
      "Someril, Prodige himself:\n",
      "Whath of innocence?\n",
      "\n",
      "MARCIUS:\n",
      "Lest, that's no do murder\n",
      "Come, my lord.\n",
      "\n",
      "RANIO:\n",
      "For didst me may false well, terry drum unview,\n",
      "By this all hence, what slopper saint, unlike be mischary,\n",
      "Speak neflows up, ere mino one to here:\n",
      "Good queen.\n",
      "\n",
      "MONTAGUE:\n",
      "You gostly's guill have to debt, is ghine allie.\n",
      "Well\n",
      "George:\n",
      "Who shall your father? wome preamed; why,\n",
      "I lay that thy losked oming; for hone\n",
      "To the poy fetch blooder hood: down of your hour,\n",
      "The stable, since thy quak.\n",
      "Farewell bring ds daughter'd\n"
     ]
    }
   ],
   "source": [
    "model.snippet('HAHA')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
